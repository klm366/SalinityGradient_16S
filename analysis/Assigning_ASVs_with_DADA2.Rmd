---
title: "Assigning ASVs with DADA2"
author: Kelly Miller
output:
  html_document: 
    code_folding: show
    theme: spacelab
    highlight: pygments
    keep_md: no
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 3
  keep_md: true  
editor_options: 
  chunk_output_type: console
date: "`r format(Sys.time(), '%B %d, %Y')`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      #Send figures generated in this file to this folder below
                      fig.path = "../figures/02_AssignASVs")
```
# Goals

  1. Infer Errors in our sequences, separately on forward and reverse reads.
  2. Assign ASVs on both forward and reverse reads separately. Apply the error model.
  3. Merge forward and reverse ASVs into "contiguous ASVs".
  4. Generate first draft of ASV count table. 
  5. Quality Trimming ASV lengths.
  6. Remove chimeras.
  7. Assign Taxonomy with Silva Database.
  8. Write out relevant files: `asv_table`, `asvs_fasta`, `tax_table`, and `sample_data`.
  
## Input
  1. Filtered fastq files generated from `01_QualityTrimming.Rmd`.
  2. Sample Name vector.
  
## Output
  1. `asv_table`
  2. `asvs_fasta`
  3. `tax_table`
  4. `sample_data`

# Set up the Environment

#Set a Seed
```{r set-seed}
set.seed(234834)
```

# Load Packages
```{r load-packages}
pacman::p_load(tidyverse, devtools, dad2, pathwork, DT, install = FALSE)
```

# Load Filtered Fastq Files
```{r load-filtered-fastqs}
  # place filtered seq files into a variable
  filtered_fastqs_path <- "data/01_DADA2/02_filtered_fastqs"
  
  # intuition check
  filtered_fastqs_path
  
  # create forward vector
  filtered_forward_reads <- 
    list.files(filtered_fastqs_path, pattern = "R1_filtered.fastq.gz",
               full.names = TRUE)
  
  # check
  filtered_forward_reads[1:5]
  
  # create reverse vector
   filtered_reverse_reads <- 
    list.files(filtered_fastqs_path, pattern = "R2_filtered.fastq.gz",
               full.names = TRUE)
   # check
   filtered_reverse_reads[1:5]
```

# Sample names 
```{r sample-names}
# Create vector of sample names from the filenames 
sample_names <- sapply(strsplit(basename(forward_reads), "_"), `[`,1) 

# Intuition Check 
head(sample_names)

```

# Error Modelling
```{r learn-errors}
  # Forward reads
  error_forward_reads <- 
    learnErrors(filtered_forward_reads, multithread = 6)
 
 # Plot
  forward_error_plot <- 
    plotErrors(error_forward_reads, nominalQ = TRUE) +
    labs(title = "Forward Reads: Error Model")

  # Reverse reads
  error_reverse_reads <- 
    learnErrors(filtered_reverse_reads, multithread = 6) 
  
  # Plot
  reverse_error_plot <- 
    plotErrors(error_reverse_reads, nominalQ = TRUE) +
    labs(title = "Reverse Reads: Error Model")
  
  # Look at the plots together
  forward_error_plot + reverse_error_plot
```

# Infer ASVs
```{r infer-ASVs}
  # Forward ASVs
  dada_forward <- 
    dada(filtered_forward_reads,
         err = error_forward_reads,
         multithread = 6)
   
  # Take a look at the data
  typeof(dada_forward)
  dada_forward$`20210602-MA-ABB1F_R1_filtered.fastq.gz`

  # Reverse ASVs
  dada_reverse <- 
    dada(filtered_reverse_reads,
         err = error_reverse_reads,
         multithread = 6)
  
  #Check data
  dada_reverse[30]

```

# Merge forward and reverse ASVs
```{r merge-ASVs}
merged_ASVs <- 
  mergePairs(dada_forward, filtered_forward_reads,
             dada_reverse, filtered_reverse_reads,
             verbose = TRUE)

# evaluate output
typeof(merged_ASVs)
length(merged_ASVs)
names(merged_ASVs)

# Inspect further
head(merged_ASVs)
merged_ASVs$`20210602-MA-ABB1F_R1_filtered.fastq.gz`

```

# Create Raw ASV Count Table
```{r raw_ASV-count-table}
# raw ASV
raw_ASV_table <- makeSequenceTable(merged_ASVs)

# Check
dim(raw_ASV_table)
typeof(raw_ASV_table)
class(raw_ASV_table)

# write out raw_ASV_table
write.table(raw_ASV_table, file = "data/01_DADA2/raw_ASV_counts.tsv",
            sep = "\t", quote = FALSE, col.names = NA)
```

# Assess the ASV Length
```{r assess-ASV-length}

# Creating a table to inspect the distribution of ASV lengths
table(nchar(getSequences(raw_ASV_table)))

# Plot
data.frame(ASV_Length = nchar(getSequences(raw_ASV_table))) %>% 
  ggplot(aes(x = ASV_Length)) +
  geom_histogram() +
  scale_x_continuous(limits = c(0, 500)) +
  labs(title = "Raw ASV Lengths",
       y = "Number of ASVs", x = "ASV Sequence Length (bps)")
```

# Trim ASVs
```{r trim-ASVs}
# Only pull ASVs that have a length of 245 BPs
raw_ASV_table_trimmed <- 
  raw_ASV_table[,nchar(getSequences(raw_ASV_table)) == 245]

# Intuition check
table(nchar(getSequences(raw_ASV_table_trimmed)))
```

# Remove Chimeras
```{r rm-chimeras}
noChimeras_ASV_table <- 
  removeBimeraDenovo(raw_ASV_table_trimmed,
                     method = "consensus",
                     multithread = 6,
                     verbose = TRUE)

# Structure of data?
dim(noChimeras_ASV_table)
dim(raw_ASV_table_trimmed)

# Intuition check
length(raw_ASV_table_trimmed)

```
# Track the number of reads DADA2 workflow

# Assign Taxonomy

# Session Information
```{r session-info}
# Ensure reproducibility 
devtools::session_info()
```